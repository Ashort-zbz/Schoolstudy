# 第一章	初识数据分析与挖掘

​        有一句话说的好，在信息爆炸的时代，信息是新的石油资源。而怎样开发这种新型的资源，就变得很重要。这是我人生的一个重要决定之一，走数据分析和挖掘这条路。而我也决定跟随时代潮流，通过Python语言来认识和熟悉这个未知的领域。（虽然被老师吐槽Python是儿童语言   (இдஇ`)不过个人觉得万变不离其宗，用什么语言不是很重要，灵魂是方法，算法。

## 1.1	数据分析和挖掘是什么？

​        数据分析和挖掘都是基于收集来的数据，应用数学、统计、计算机等技术抽取数据中的有用信息，进而为决策提供依据和知道方向。

​        随着数据时代的蓬勃发展，越来越多的企业事业单位开始认识到数据的重要性，并通过各种手段进行数据收集。例如，使用问卷调查方法获取用户对产品的评价或改善意见；通过每一次的实验获得产品性能的改良状况；基于各种设备记录空气质量状况、人体健康状况、机器运行寿命等，通过网页或APP记录用户的每一次登录、浏览、交易、评论等操作；基于数据接口、网络爬虫等手段获取万维网中的公开数据；甚至是企业间的合作实现多方数据的共享。他们花大量人力、物力获取各种数据的主要目的就是通过数据分析和挖掘的手段实现数据的变现，否则囤积的数据就是资源的浪费。 

##    1.2	数据分析与挖掘的应用领域

​        现在数据充斥在各个领域，如庞大的互联网产业，包括各种电商平台、游戏平台、社交平台、中介平台等；金融行业，包含银行、P2P、互联网金融等；影响国民的教育、医疗行业；各类乙方数据服务行业，传统行业，如房地产、餐饮、美容等。这些行业都需要借助数据分析和挖掘技术来指导下一步的决策方向。具体的应用场景就不再多说。

## 1.3	数据分析与挖掘的区别

| 差异角度 |                                      |                                          |
| -------- | ------------------------------------ | ---------------------------------------- |
| 定义     | 描述和探索性分析，评估现状和修正不足 | 技术性的“采矿”过程，发现未知的模式和规律 |
| 侧重点   | 实际的业务知识                       | 技术挖掘的落地，完成“采矿”过程           |
| 技能     | 统计学、数据库、Excel、可视化等      | 过硬的数学功底和编程技术                 |
| 结果     | 需结合业务知识解读统计结果           | 模型或规则                               |

​        从广义的角度来说，数据分析的范畴会更大一些，涵盖了数据分析和数据挖掘两个部分。数据分析就是针对搜集来的数据运用基础探索、统计分析、深层挖掘等方法，发现挖掘中有用的信息和未知的规律与模式，进而为下一步的业务决策提供理论与实践依据。

接下来具体阐述一下这几个方面的差异：

- 从定义说明出发：数据分析采用适当的统计学方法，**对搜集来的数据进行描述性分析和探索性分析**，并从描述和探索的结果中发现数据背后存在的价值信息，用以评估现状和修正当前的不足；数据挖掘则广泛交叉数据库知识、统计学、机器学习、人工智能等方法，对搜集来的数据进行**“采矿”**，发现其中未知的规律和有用的知识，进一步应用于数据化运营，让数据产生更大的价值。
- 从侧重点出发：数据分析**更侧重于实际的业务知识**，如果将数据和业务分开，往往会导致数据的输出不是业务所需，业务的需求无法通过数据体现，故数据分析需要两者的紧密结合，实现功效的最大化；数据挖掘则**更侧重于技术的实现**，对业务知识的熟练度并没有很高的要求，如何实现在海量的数据中发现未知的模式和规律，是数据挖掘的目的所在，只有技术过硬，才能实现挖掘项目的落地。
- 从掌握的技能出发：数据分析一般要求具备基本的统计学知识、数据库操作技能、Excel报表开发和常用可视化图表展现的能力，就可以解决工作中的分析任务；数据挖掘**对数学功底和编程能力有较高的要求**，数学功底是数据挖掘、机器学习、人工智能等方面的基础，没有好的数学功底，在数据挖掘领域是走不远的，编程能力是从数据中发现未知模式和规律的途径，没有编程技能，就无法实现算法的落地。
- 从输出的结果出发：数据分析更多的是**统计描述结果的呈现**，如平均水平、总体趋势、差异对比、数据转化等，这些结果都必须结合业务知识进行解读，否则一组数据是没有任何实际意义的；数据挖掘则更多的是**模型或规则的输出**，通过模型或规则可对未知标签的数据进行预测，如预测交通的畅通度（预测模型）、判别用户是否相应某种营销活动（分类算法）；通过模型或规则实现智能的商业决策，如推荐用户可能购买的商品（推荐算法）、划分产品所属的群类（聚类算法）等。

## 1.4    数据挖掘的流程

### 1.4.1    明确目标

​        在实施数据挖掘前必须明确自己需要解决什么问题，然后才可以有的放矢。因此明确目标即数据挖掘流程的第一步。

### 1.4.2    数据搜集

​        当明确好需要处理的问题之后，下一步就要规划哪些数据可能会影响到这些问题的答案，即数据的搜集过程。这是很关键的一步。

### 1.4.3    数据清洗

即使数据搜集上来，也必须要保证数据“干净”，因为数据质量的高低会影响最终结果的准确性。尤其是在你搜集到大量数据的时候，这个步骤就显得尤为重要。如何从上千万条数据中清洗，这是个问题。在这里列出数据缺失的类型。

- 缺失值：由于个人隐私或设备故障导致某些观测在维度上的漏缺，一般称为缺失值。缺失值的存在可能会导致模型结果的错误，所以针对缺失值可考虑删除法，替换法或者插值法解决。
- 异常值：一般指远离正常样本的观测点，它们的存在同样会影响模型的准确性，故可以考虑删除或单独处理。当然在某些场景下，异常值是有益的，例如通过异常值可以筛选出钓鱼网站。
- 数据的不一致性：主要是由于不同的数据源或系统并发不同步所导致的数据不一致性，例如两个数据源中数据单位的不一致（一个以元为单位，另一个以万元为单位）；系统并发不同步导致一张电影票被多个用户购买。针对这种情况则需要不同数据源的数据更新（SQL）或系统实现同步并发。
- 量纲的影响：由于某些模型容易受到不同量纲的影响，因此需要通过数据的标准化方法将不同量纲的数据进行统一处理，如将数据都压缩至0~1的范围。
- 维度灾难：当采集来的数据包含上百乃至成千上万的变量时，往往会提高模型的复杂度，进而影响模型的运行效率，故需要采用方差分析法、相关系数法、递归特征消除法、主成分分析法等手段实现数据的特征提取或降维。

### 1.4.4    构建模型

​        “万事俱备，直欠建模”！据不完全统计，建模前的数据准备将占整个数据挖掘流程80%左右的时间，“地基不牢，地动山摇“。接下来，在数据准备充分的前提下，需要考虑企业面临的痛点或难题可以通过什么类型的挖掘模型解决。

### 1.4.5    模型评估

​        到此阶段，已经完成了数据挖掘流程中的绝大部分工作，并且通过数据得到解决得到解决问题的多个方案（模型），接下来要做的就是从这些模型中挑选出最佳的模型，主要目的就是让这个最佳模型能够更好地反应数据的真实性。例如，对于预测或分类类型的模型，即使在其在训练集中的表现很好，但在测试集中结果一般，则说明该模型存在过拟合现象，需要从数据或或模型角度做进一步修正。

### 1.4.6    应用部署

​        通常挖掘出来的模式或者规律是给真正的业务方或客户服务的，需要将这些模式重新部署到系统。

## 1.5     常用数据分析与挖掘工具

1. R语言——具备灵活的数据操作、高效的向量化运算、优秀的数据可视化等优点。**是一颗优秀的数据挖掘工具，用户可以借助强大的第三方扩展包，实现各种数据挖掘算法的落地**。
2. Python——原本主要是应用于系统维护和网页开发，但随着大数据时代到来，数据挖掘、机器学习、人工智能等技术越发热门，进而促使Python进入数据科学领域。同样拥有各种五花八门的第三方模块，可以利用这些模块完成数据科学中的任务。如：**pandas、statsmodels、scipy等模块用于数据处理和统计分析；matplotlib、seaborn、boken、等模块实现数据的可视化功能；sklearn、PyML、keras、tensorflow等模块实现数据挖掘、深度学习等操作。**
3. Weka——公开的数据挖掘平台，包含数据预处理、数据可视化等功能，以及各种常用的回归、分类、聚类、关联规则等算法。**对于不擅长编程的用户，可通过Weka的图形化界面完成分析或挖掘的工作。**
4. SAS——开发出来是是为了解决生物统计方面的数据分析。在1976年成立SAS软件研究所，经过多年的完善，**最终在国际上被誉为统计分析的标准软件**，受到各个领域的广泛应用。由数十个模块构成，其中**Base为核心模块，主要用于数据的管理和清洗**、GHAPH模块可以帮助用户实现数据可视化、STAT模块则涵盖所有实用统计分析方法、EM模块则更是人性化的图形界面，通过托拉拽的方式实现各种常规挖掘算法的应用。
5. SPSS——是世界上**最早的统计分析软件**，于1968年斯坦福大学的三个研究生开发。可通过SPSS的界面实现数据的统计分析和建模、数据可视化及报表输出。简单的操作受到众多喜爱。除此之外，SPSS还有一款**Modeler工具**，前身是Clementine，2009年被IBM收购。该工具充分体现了数据挖掘的各个流程，例如数据的导入、清洗、探索性分析、模型选择、模型评估和结果输出，用户可以基于界面化的操作完成数据挖掘的各个环节。

以上5款较为常用的数据分析与挖掘工具，其中R语言、Python和Weka都属于开源工具。
